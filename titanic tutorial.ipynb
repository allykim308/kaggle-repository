{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T06:37:36.210135Z","iopub.status.idle":"2022-07-08T06:37:36.210814Z","shell.execute_reply.started":"2022-07-08T06:37:36.210623Z","shell.execute_reply":"2022-07-08T06:37:36.210643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np # numpy는 행열 연산 라이브러리\nimport pandas as pd # pandas는 데이터 분석 라이브러리\nimport matplotlib.pyplot as plt # matplotlib는 데이터 시각화라이브러리(그래프)\nimport seaborn as sns #seaborn 은 시각화 라이브러리\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5)  \nimport missingno as msno #결측치를 확인하는데 쓰는 라이브러리\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\ndf_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.211918Z","iopub.status.idle":"2022-07-08T06:37:36.212536Z","shell.execute_reply.started":"2022-07-08T06:37:36.212348Z","shell.execute_reply":"2022-07-08T06:37:36.212367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. 데이터셋 확인 - 대부분의 캐글 데이터들은 잘 정제되어있습니다. 하지만 가끔 null data가 존재합니다. 이를 확인하고, 향후 수정합니다.\n2. 탐색적 데이터 분석(exploratry data analysis) - 여러 feature들을 개별적으로 분석하고 feature 들 간의 상관관계를 확인합니다. 여러 시각화 틀을 사용하여 insight 를 얻습니다.\n3. feature engineerin - 모델을 세우기에 앞서, 모델의 선는을 높일 수 있도록 deature들을 engineering합니다. one-hot encoding, class로 나누기, 구가능로 나누기, 텍스트 데이터 처리등을 합니다.\n4. model 만들기 = sklearn을 사용해 모델을 만듭니다.파이썬에서 머신러닝을 할 때는 skleanrn을 사용하면 수많은 알고리즘을 일관된 문법으로 사용할 수 있습니다. 물론 딥러닝을 위해 tensorflow, pytorch등을 사용할 수도 있습니다.\n5. 모델 학습 및 예측 - trainset을 가지고 모델을 학습시킨 후, testset을 가지고 prediction 합니다.\n6. 모델 평가 - 예측 성능이 원하는 수준인지 판단합니다. 풀려는 문제에 따라 모델을 평가하는 방식도 달라집니다. 학습된 모델이 어떤 것을 학습하여쓴ㄴ지 확인해봅니다.\n\n\n1. Dataset 확인\n- 파이썬에서 테이블화 된 데이터를 다루는 데 가장 최적화되어 있으며, 많이 쓰이는 라이브러리는 pandas입니다.\n- pandas를 사용하여 데이터셋의 간단한 통계적 분석부터, 복잡한 처리들을 간단한 메소드를 사용하여 해낼 수 있습니다.\n- 파이썬으로 데이터를 분석한다면 반드시 능숙해져야 하는 라이브러리. 반복 또 반복 권장\n- 캐글에서 데이터셋을 보통 train, testset으로 나뉘어 있습니다.\n- 우리가 다루는 문제에서 feature는 Pclass, Age, SibSp, Parch, Fare 이며 에측하려는 target label 은 Survived 입니다. ","metadata":{}},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.213582Z","iopub.status.idle":"2022-07-08T06:37:36.214181Z","shell.execute_reply.started":"2022-07-08T06:37:36.213976Z","shell.execute_reply":"2022-07-08T06:37:36.213995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.215262Z","iopub.status.idle":"2022-07-08T06:37:36.215884Z","shell.execute_reply.started":"2022-07-08T06:37:36.215695Z","shell.execute_reply":"2022-07-08T06:37:36.215715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null Data Check\nfor col in df_train.columns:\n    msg='column: {:>10}\\t Percent of Nan value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum()/df_train[col].shape[0]))\n    print(msg)                                                                                                               \n    #여기서 shape[0]은 행의 갯","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.216978Z","iopub.status.idle":"2022-07-08T06:37:36.217646Z","shell.execute_reply.started":"2022-07-08T06:37:36.217453Z","shell.execute_reply":"2022-07-08T06:37:36.217473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null Data Check\nfor col in df_test.columns:\n    msg='column: {:>10}\\t Percent of Nan value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum()/df_test[col].shape[0]))\n    print(msg)                                                                                                               \n    #여기서 shape[0]은 행의 갯","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.218749Z","iopub.status.idle":"2022-07-08T06:37:36.219569Z","shell.execute_reply.started":"2022-07-08T06:37:36.219354Z","shell.execute_reply":"2022-07-08T06:37:36.219376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train, test set 에서 Age(둘 다 약 20%), Cabin(둘달 약 80%), Embarked(train에서만 0.22) null data 가 존재하는 것을 볼 수 있습니다.\n- MANO라는 라이브러리를 사용하면 null data의 존재를 더 쉽게 볼수 있습니다.","metadata":{}},{"cell_type":"code","source":"msno.matrix(df=df_train.iloc[:,:], figsize=(8,8), color = (0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.220708Z","iopub.status.idle":"2022-07-08T06:37:36.221385Z","shell.execute_reply.started":"2022-07-08T06:37:36.221179Z","shell.execute_reply":"2022-07-08T06:37:36.221201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df_train.iloc[:,:], figsize=(8,8), color = (0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.222536Z","iopub.status.idle":"2022-07-08T06:37:36.223189Z","shell.execute_reply.started":"2022-07-08T06:37:36.22298Z","shell.execute_reply":"2022-07-08T06:37:36.223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df=df_test.iloc[:,:], figsize =(8,8), color = (0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.224311Z","iopub.status.idle":"2022-07-08T06:37:36.224921Z","shell.execute_reply.started":"2022-07-08T06:37:36.22472Z","shell.execute_reply":"2022-07-08T06:37:36.224739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.2 Target Label 확인\n- target label이 어떤 distribution을 가지고 있는 지 확인해 봐야 합니다.\n- 지금같은 binary classification 문제의 경우에서, 1과 0의 분포가 어떠냐에 따라 모델의 평가 방법이 달라질 수 있습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize =(18, 8))\ndf_train['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct = '%1.1f%%', ax = ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=df_train, ax=ax[1])\nax[1].set_title('Count plot - Survived')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.225954Z","iopub.status.idle":"2022-07-08T06:37:36.226528Z","shell.execute_reply.started":"2022-07-08T06:37:36.226333Z","shell.execute_reply":"2022-07-08T06:37:36.226354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 38.4% 가 살아남았습니다.\n- target label의 분포가 제법 균일합니다. 불균일한 경우, 예를 들어 100중 1이 99, 0이 1개인 경우에는 만약 모델이 모든것을 1이라 해도 정확도가 99%가 나오게 됩니다. 0을 찾는 문제라면 이 모델은 원하는 결과를 줄 수 없게 됩니다. 지금 문제에서는 그렇지 않습니다.\n2. Exploratory data ananlysis\n- 데이터 분석에는 적절한 시각화가 필요합니다.\n- 시각화 라이브러리는 matplotlib, seaborn, plotly 등이다. 특정 목적에 맞는 소스코드를 정리해 두면 편리합니다.\n2.1 Pclass\n- Pclass 는 ordinal,서수형 데이터입니다. 카테고리이면서, 순서가 있는 데이터입니다.\n- 먼저 Pclass에 따른 생존률의 차이를 살펴보겠습니다. 엑셀의 피벗 차트와 유사한 작업을 하게 되는데, pandas dataframe에서는 groupby를 사용하면 쉽게 할 수 있습니다. 또한 pivot이라는 메소드도 있습니다.\n- 'Pclass', 'Survived'를 가져온 후 pclass로 묶습니다. 그러고 나면 각 pclass 마다 0, 1 dl count 되는데, 이를 평균내면 각 pclass 별 생존률이 나옵니다.\n- 아래와 같이count()를 하면, 각 class에 몇명이 있는지 확인할 수 있으며,sum()을 하면, 216 명중 생존한 (survived=1)사람의 총합을 주게 됩니다.\n","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).count()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.227529Z","iopub.status.idle":"2022-07-08T06:37:36.227986Z","shell.execute_reply.started":"2022-07-08T06:37:36.227741Z","shell.execute_reply":"2022-07-08T06:37:36.22777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.229526Z","iopub.status.idle":"2022-07-08T06:37:36.230034Z","shell.execute_reply.started":"2022-07-08T06:37:36.229719Z","shell.execute_reply":"2022-07-08T06:37:36.229737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-pandas의 crosstab을 사용하면 좀 더 위과정을 수워할게 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap = 'summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.232083Z","iopub.status.idle":"2022-07-08T06:37:36.232967Z","shell.execute_reply.started":"2022-07-08T06:37:36.232746Z","shell.execute_reply":"2022-07-08T06:37:36.232771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-grouped객체에 mean()을 하게 되면, 각 틀래스별 생존률을 얻을 수 있습니다. class 1이면 아래와 같습니다.  \n80/(80+136)≈0.63","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean().sort_values(by='Survived', ascending = False).plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.23448Z","iopub.status.idle":"2022-07-08T06:37:36.23551Z","shell.execute_reply.started":"2022-07-08T06:37:36.235302Z","shell.execute_reply":"2022-07-08T06:37:36.235325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- Pclass가 좋을 수록 생존률이 높은것을 확인할 수 있습니다.\n- 좀 더 보기 쉽게 그래프를 그려보겠습니다. seaborn의 countplot을 이용하면 특정 label에 따른 개수를 확인해볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"y_position = 1.02\nf, ax = plt.subplots(1,2, figsize=(18,8)) # figure 값과 axes값을 받으수 있다.\ndf_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])\nax[0].set_title('Number of Passengers By Pclass', y=y_position)\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=df_train, ax = ax[1])\nax[1].set_title('Pclass: Survived vs Dead', y=y_position)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.237078Z","iopub.status.idle":"2022-07-08T06:37:36.237662Z","shell.execute_reply.started":"2022-07-08T06:37:36.237382Z","shell.execute_reply":"2022-07-08T06:37:36.237408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 클래스가 높을수록 생존률이 높은걸 확인할 수 있다. Pclass 1,2,3,순서대로 63%, 48%, 25% 입니다. 우리는 생존에 Pclass가 큰 영향을 미친다고 생각해볼 수 있으며, 나중에 모델을 세울때 이feature를 사용하는 것이 좋을 것이라 판단할 수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"2.2 Sex\n- 이번에는 성별로 생존률이 어떻게 달라지는 지 확인해보겠습니다.\n- 마찬가로 pandas groupby와 seaborn countplot을 사용해서 시각화 해봅시다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(18, 8))\ndf_train[['Sex','Survived']].groupby(['Sex'], as_index=True).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data = df_train, ax=ax[1])\nax[1].set_title('Sex: Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.23999Z","iopub.status.idle":"2022-07-08T06:37:36.240892Z","shell.execute_reply.started":"2022-07-08T06:37:36.240569Z","shell.execute_reply":"2022-07-08T06:37:36.240599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피 여자가 생존률이 높습니다.","metadata":{}},{"cell_type":"code","source":"df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.242558Z","iopub.status.idle":"2022-07-08T06:37:36.243771Z","shell.execute_reply.started":"2022-07-08T06:37:36.243474Z","shell.execute_reply":"2022-07-08T06:37:36.243503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Sex'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.245192Z","iopub.status.idle":"2022-07-08T06:37:36.245604Z","shell.execute_reply.started":"2022-07-08T06:37:36.245422Z","shell.execute_reply":"2022-07-08T06:37:36.24544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- Plcass와 마찬가지로 Sex도 예측 모델에 쓰일 중요한 feature임을 알수 있습니다.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"2.3 Both Sex and Pclass\n\n    -이번에는 Sex, Pclass두가지에 관하여 생존이 어떻게 달라지는 지 확인해 봅시다.\n    - seaborn의 factorplot을 이용하면, 손쉽게 3개의 차원으로 이루어진 그래프를 그릴수 있습니다.\n-seaborn의 ","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', data=df_train, size=6, aspect=1.5)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.247312Z","iopub.status.idle":"2022-07-08T06:37:36.248321Z","shell.execute_reply.started":"2022-07-08T06:37:36.248056Z","shell.execute_reply":"2022-07-08T06:37:36.248078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    - 모든 클래스에서 female 이 살 확률이 male보다 높은 걸 알 수 있습니다.\n    - 또한 남자, 여자 상관없이 클래스가 높을 수록 살 확률이 높습니다.\n    - 위 그래프는 hue 대신 column으로 하면 아래와 같습니다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x='Sex', y='Survived', col='Pclass', data=df_train, saturat=.9, size=9, aspect=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.249514Z","iopub.status.idle":"2022-07-08T06:37:36.249878Z","shell.execute_reply.started":"2022-07-08T06:37:36.249702Z","shell.execute_reply":"2022-07-08T06:37:36.24972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****2.4 Age","metadata":{}},{"cell_type":"code","source":"print('제일 나이 많은 탑승객: {:.1f} Years'.format(df_train['Age'].max()))\nprint('제일 어린 탑승객: {:.1f} Years'.format(df_train['Age'].min()))\nprint('탑승객 평균 나이: {:.1f}Years'.format(df_train['Age'].mean()))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.250948Z","iopub.status.idle":"2022-07-08T06:37:36.25135Z","shell.execute_reply.started":"2022-07-08T06:37:36.251131Z","shell.execute_reply":"2022-07-08T06:37:36.251176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- 생존에 따른 Age의 histogram을 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(9,5))\nsns.kdeplot(df_train[df_train['Survived']==1]['Age'], ax=ax)\nsns.kdeplot(df_train[df_train['Survived']==0]['Age'], ax = ax)\nplt.legend(['Survived==1', 'Survived==0'])\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.252463Z","iopub.status.idle":"2022-07-08T06:37:36.253264Z","shell.execute_reply.started":"2022-07-08T06:37:36.25301Z","shell.execute_reply":"2022-07-08T06:37:36.253033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피 생존자 중에 나이가 어린 경우가 많음을 볼 수 있습니다.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\ndf_train['Age'][df_train['Pclass'] == 1].plot(kind='kde')\ndf_train['Age'][df_train['Pclass'] == 2].plot(kind='kde')\ndf_train['Age'][df_train['Pclass'] == 3].plot(kind='kde')\n\nplt.xlabel('Age')\nplt.title('Age Distribution within classes')\nplt.legend(['1st Class', '2nd Class', '3rd Class'])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.254852Z","iopub.status.idle":"2022-07-08T06:37:36.255514Z","shell.execute_reply.started":"2022-07-08T06:37:36.25531Z","shell.execute_reply":"2022-07-08T06:37:36.25533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- class 가 높을 수록 나이 많은 사람의 비중이 커짐\n- 나이대가 변하면서 생존률이 어떻게 되는 지 보려고 합니다.\n나이 범위를 점점 넓혀가며, 생존률이 어떻게 되는지 한번 봅시다.","metadata":{}},{"cell_type":"code","source":"cummulate_survival_ratio = []\nfor i in range(1,80):\n    cummulate_survival_ratio.append(df_train[df_train['Age']< i]['Survived'].sum()/len(df_train[df_train['Age']<i]['Survived']))\nplt.figure(figsize=(7,7))\nplt.plot(cummulate_survival_ratio)\nplt.title('Survival rate change depending on range of Age', y=1.02)\nplt.ylabel('Survival rate')\nplt.xlabel('Range of Age(0~x)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.257366Z","iopub.status.idle":"2022-07-08T06:37:36.257757Z","shell.execute_reply.started":"2022-07-08T06:37:36.257576Z","shell.execute_reply":"2022-07-08T06:37:36.257593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피, 나이가 어릴수록 생존률이 확실히 높은 것을 확인할 수 있습니다.\n- 우리는 이 나이가 중요한 feature로 쓰일 수 있음을 확인했습니다.","metadata":{}},{"cell_type":"markdown","source":"# 2.5 Plcass, Sex, Age\n- 지금까지 본 sex, Plcass, Age, Survived 모두에 대해서 보고 싶습니다. 이를 쉽게 그려주는 것이 seaborn의 violinplot입니다.\n- x 축은 우리가 나눠서 보고싶어하는 case(여기선 Plcass, Sex)를 나타내고, y축은 보고 싶어하는 distribution(Age)입니다.\n- 한번 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,2,figsize=(18,8))\nsns.violinplot(\"Pclass\",\"Age\", hue = \"Survived\", data=df_train, scale='count', split=True, ax = ax[0])\nax[0].set_title('Pclass and Ave vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot(\"Sex\", \"Age\", hue = \"Survived\", data=df_train, scale='count', split=True, ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.260101Z","iopub.status.idle":"2022-07-08T06:37:36.260879Z","shell.execute_reply.started":"2022-07-08T06:37:36.260618Z","shell.execute_reply":"2022-07-08T06:37:36.260638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- 왼쪽 그림은 Pclass 별로 Age의 Distribution이 어떻게 다른지, 거기에 생존 여부에 따라 구분한 그래프입니다.\n- 오른쪽 그림도 마찬가지 Sex, 생존에 따른 distribution이 어떻게 다른지 보여주는 그래프입니다.\n- 생존만 봤을때 모든 클래스에서 나이가 어릴수록 생존을 많이 한것을 볼 수있습니다.\n- 오른쪽 그림에서 보면 명확히 여자가 생존을 많이 한것을 볼수 있습니다.\n- 여성과 아이를 먼저 챙긴 것을 볼수 있습니다.\n\n\n\n# 2.6 Embarked\n\n- Embarked는 탑승한 항국를 나타냅니다.\n- 위에서 해왔던 것과 비슷하게 탑승한 곳에 따르 생존을 보겠습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1,1,figsize=(7,7))\ndf_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.262844Z","iopub.status.idle":"2022-07-08T06:37:36.263259Z","shell.execute_reply.started":"2022-07-08T06:37:36.263052Z","shell.execute_reply":"2022-07-08T06:37:36.26307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피, 조금의 차이는 있지만 생존률은 좀 비슷한 거 같습니다. 그래도 c가 제일 높군요.\n- 모델에 얼마나 큰 영향을 미칠지는 모르겠지만, 그래도 사용하겠습니다.\n사실, 모델을 만들고 나면 우리가 사용한 feature들이 얼마나 중요한 역할을 했는지 확인해볼 수 있습니다. 이는 추후에 모델을 만들고 난 다음에 살펴볼 것입니다.\n- 다른 feature로 split하여 한번 살펴보겠습니다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(2,2,figsize=(20,15))\nsns.countplot('Embarked', data=df_train, ax = ax[0,0])\nax[0,0].set_title('(1) No. Of Passengers Boarded')\nsns.countplot('Embarked', hue='Sex', data=df_train, ax = ax[0,1])\nax[0,1].set_title('(2) Male-Female Split for Embarked')\nsns.countplot('Embarked', hue = 'Survived', data=df_train, ax=ax[1,0])\nax[1,0].set_title('(3) Embarked vs Survived')\nsns.countplot('Embarked', hue='Pclass', data=df_train, ax=ax[1,1])\nax[1,1].set_title('(4) Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.264877Z","iopub.status.idle":"2022-07-08T06:37:36.265308Z","shell.execute_reply.started":"2022-07-08T06:37:36.265078Z","shell.execute_reply":"2022-07-08T06:37:36.265095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Figure(1) - 전체적으로 봤을 때  S에서 가장 많은 사람이 탑승했습니다.\n- Figure(2)- C와 Q는 남녀 비율이 비슷하고 S는 남자가 더 많습니다.\n- Figure(3)- 생존률이 S 경우 많이 낮은것을 볼수 있습니다.\n- Figure(4) Class로 split해서 보니 C가 생존률이 높은건 클래스가 높은 사람이 많이 타서 그렇습니다. S는 3rd class 가 많아서 생존률이 낮게 나옵니다.\n\n# 2.7 Family-SibSp(형제, 자매) + ParCh(부모, 자녀)\n- Sibsp 와 ParCh를 합하면 Family가 될것입니다. Family로 합쳐서 분석해봅시다.\n","metadata":{}},{"cell_type":"code","source":"df_train['FamilySize'] = df_train['SibSp']+df_train['Parch']+1\ndf_test['Familysize']= df_test['SibSp']+df_test['Parch']+1\nprint(\"Maximum size of Family: \", df_train['FamilySize'].max())\nprint(\"Minimim size of Family: \", df_train['FamilySize'].min())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.267619Z","iopub.status.idle":"2022-07-08T06:37:36.26801Z","shell.execute_reply.started":"2022-07-08T06:37:36.26783Z","shell.execute_reply":"2022-07-08T06:37:36.267846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- FamilSize와 생존의 관계를 한번 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(1,3,figsize = (40,10))\nsns.countplot('FamilySize', data=df_train, ax=ax[0])\nax[0].set_title('(1) No. of Passengers Boarded', y = 1.02)\n\nsns.countplot('FamilySize', hue = 'Survived', data = df_train, ax = ax[1])\nax[1].set_title('(2) Survived countplot depending on FamilySize', y = 1.02)\ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])\nax[2].set_title('(3) Survived rate depending on FamilySize', y = 1.02)\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.269773Z","iopub.status.idle":"2022-07-08T06:37:36.270601Z","shell.execute_reply.started":"2022-07-08T06:37:36.270311Z","shell.execute_reply":"2022-07-08T06:37:36.27034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Figure(1) - 가족ㄴ크기가 1~11까지 있음을 볼수 있습니다. 대부분 1명이고 그다음으로 2,3,4명입니다.\n- Figure(2),(3)- 가족 크기에 따른 생존 비교입니다. 가족이 4명인 경우가 가장 생존률이 높습니다. 가족수가 많아질수록(5,6,7,8,11), 생존률이 낮아지네요. 가족수가 너무 작아요(1), 너무 커도 생존률이 작네요. 3~4명 선에서 생존률이 높은 걸 확인할 수 있습니다.\n\n# 2.8 Fare\n-Fare는 탑승 요금이며, continous feature입니다. 한번 histogram을 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.272777Z","iopub.status.idle":"2022-07-08T06:37:36.273531Z","shell.execute_reply.started":"2022-07-08T06:37:36.273243Z","shell.execute_reply":"2022-07-08T06:37:36.273272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-보시다시피, distribution,이 매우 비대칭인것을 알수 있습니다. (high skewness). 만약 이대로 모델에 넣어준다면 자칫 모델이 잘못 학습할 수동 ㅣㅆ습니다. 몇개 없는 outlier에 대해서 너무 민감하게 반응한다면 실제 예측 시에 좋지 못한 결과를 부를 수 있습니다.\n-outlier의 영향을 줄이기 위해 Fare에 log를 취하겠습니다.\n- 여기서 우리는 pandas의 유용한 기능을 사용할 겁니다. dataFrame의 특정 columns에 공통된 작업(함수)를 적용하고 싶으면 아래의 map, 또는 apply를 사용하면 매우 손쉽게 적용할 수 있습니다.\n- 우리가 지금 원하는 것은 Fare columns 의  데이터 모두를 log값을 취하는 것인데, 파이썬의 간단한 lambda 함수를 이용해 간단한 로그를 적용하는 함수를 map 에 인수로 넣어주면, Fare columns데이터에 그대로 적용이 됩니다. 매우 유용한 기능이니 꼭 숙지하세요.","metadata":{}},{"cell_type":"code","source":"df_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean() \ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.275674Z","iopub.status.idle":"2022-07-08T06:37:36.27661Z","shell.execute_reply.started":"2022-07-08T06:37:36.276325Z","shell.execute_reply":"2022-07-08T06:37:36.276352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.278346Z","iopub.status.idle":"2022-07-08T06:37:36.279322Z","shell.execute_reply.started":"2022-07-08T06:37:36.278985Z","shell.execute_reply":"2022-07-08T06:37:36.279012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-log를 취하니 이제 비대칭성이 많이 사라진 것을 볼수 있습니다. \n-우리는 이런 작업을 사용해 모델이 좀 더 좋은 성능을 내도록 할 수 있습니다.\n- 사실 방금한 것은 feature engineering에 들어가는 부분인데 여기서 작업했습니다.\n- 모델을 학습시키기 위해, 그리고 그 모델의 성능을 높이기 위해 feature 들에 여러 조작을 가하거나, 새로운 feature를 추가하는 것을 feature engineering 이라고 하는데, 우리는 이제 그것을 살표볼 것입니다.\n\n\n# 2.9 Cabin\n- 이 feature 는 NaN 이 대략 80%이므로, 생존에 영향을 미칠 중요한 정보를 얻어내기가 쉽지는 않습니다.\n- 그러므로 우리가 세우려는 모델에 포함시키지 않도록 하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.28092Z","iopub.status.idle":"2022-07-08T06:37:36.28184Z","shell.execute_reply.started":"2022-07-08T06:37:36.281555Z","shell.execute_reply":"2022-07-08T06:37:36.281583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.10 Ticket\n-이 feature는 NaN은 없습니다. 일단 string data이므로 우리가 어떤 작업들을 해주어야 실제 모델에 사용할 수 있는데, 이를 위해선 사실 아이디어가 필요합니다.","metadata":{}},{"cell_type":"code","source":"df_train['Ticket'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.283428Z","iopub.status.idle":"2022-07-08T06:37:36.284024Z","shell.execute_reply.started":"2022-07-08T06:37:36.283837Z","shell.execute_reply":"2022-07-08T06:37:36.283856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피, Ticket number는 매우 다양합니다. 우리는 여기서 어떤 특징을 이끌어내서 생존과 연결시킬 수 있을까요?\n- 여러분이 직접 한번 아이디어를 내보세요! 이것이 본격적인 캐글 레이스의 시작점입니다.\n- 이 튜토리얼에서는 튜토리얼이니 일단 ticket은 넘기도록 하겠습니다. 튜토리얼을 끝낸 후, 여러분의 모델의 성능을 향상시키기 위해 ticket에서 정보를 이끌어내는 것도 좋겠네요.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# # # 타이타닉 투토리얼 2\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import Series\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) # 이 두줄은 본 필자가 항상 쓰는 방법입니다. matplotlib 의 기본 scheme 말고 seaborn scheme 을 세팅하고, 일일이 graph 의 font size 를 지정할 필요 없이 seaborn 의 font_scale 을 사용하면 편합니다.\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n%matplotlib inline\n\ndf_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')\ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 # 자신을 포함해야하니 1을 더합니다\n\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.285073Z","iopub.status.idle":"2022-07-08T06:37:36.285466Z","shell.execute_reply.started":"2022-07-08T06:37:36.285284Z","shell.execute_reply":"2022-07-08T06:37:36.285301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # # # # 3. Feature and engineering","metadata":{}},{"cell_type":"markdown","source":"- 본격적인 featuyre engineering 을 시작해보겠습니다.\n- 가장 먼저, dataset에 존재하는 nulldata를 채우려고 합니다.\n- 아무 숫자로 채울 수는 없고, null data 를 포함하는 feature의 statstics 를 참고하거나 다른 아이디어를 짜내어 채울 수 있습니다.\n- 널 데이터를 어떻게 채우느냐에 따라 모델의 성능이 좌지우짇될 수 있기 때문에, 신경써줘야 할 부분입니다.\n- Feature Engineering 은 실제 모델의 학습에 쓰려고 하는 것이므로, train분만 아니라 test도 똑같이 적용해주어야 합니다. 잊지맙시다.\n\n\n\n# # # #3. 1Fill Null \n#     3.1.1 Fill Null in Age using title\n- Age 에는 널 데이터가 177개나 있습니다. 이를 채울 수 있는 여러 아이디어가 있을 것인데, 여기서 우리는 title + statistics 를 사용해 보겠습니다.\n- 영어에서는 Miss, Mrr, Mrs 같은 title이 존재합니다. 각 탑승객의 이름에는 꼭 이런 title 이 들어가게 되는데 이를 사용해보겠습니다.\n- pandas series 에는 data 를 string 으로 바꿔주는 str method, 거기에 정규표현식을 적용하게 해주는 extract method가 있습니다. 이를 사용하여 title 을 쉽게 추출할 수 있습니다. title을 Initial column에 저장하겠습니다","metadata":{}},{"cell_type":"code","source":"df_train['Initial']= df_train.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n    \ndf_test['Initial']= df_test.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.28672Z","iopub.status.idle":"2022-07-08T06:37:36.287084Z","shell.execute_reply.started":"2022-07-08T06:37:36.286911Z","shell.execute_reply":"2022-07-08T06:37:36.286929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- pandas 의 crosstab 을 이용하여 우리가 추출한 Initial 과 Sex 간의 count 를 살펴봅시다.","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r') #Checking the Initials with the Sex","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.289034Z","iopub.status.idle":"2022-07-08T06:37:36.289416Z","shell.execute_reply.started":"2022-07-08T06:37:36.289239Z","shell.execute_reply":"2022-07-08T06:37:36.289257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- 위의 테이블을 참고하여, 남자, 여자가 쓰는 initial을 구분해 보겠습니다. replace메소드를 사용하면 특정 데이터값을 원하는 값으로 치환해줍니다.","metadata":{}},{"cell_type":"code","source":"df_train['Initial'].replace(['Mlle','Mme', 'Ms', 'Dr','Major', 'Lady','Countess', 'Jonkheer', 'Col', 'Rev', 'Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\ndf_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.291486Z","iopub.status.idle":"2022-07-08T06:37:36.291857Z","shell.execute_reply.started":"2022-07-08T06:37:36.291687Z","shell.execute_reply":"2022-07-08T06:37:36.291704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.293499Z","iopub.status.idle":"2022-07-08T06:37:36.293857Z","shell.execute_reply.started":"2022-07-08T06:37:36.293691Z","shell.execute_reply":"2022-07-08T06:37:36.293707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 여성과 관계가 있는 Miss, Mr. Mrs. 가 생존률이 높은 것을 볼수 있습니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial')['Survived'].mean().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.295125Z","iopub.status.idle":"2022-07-08T06:37:36.295538Z","shell.execute_reply.started":"2022-07-08T06:37:36.295348Z","shell.execute_reply":"2022-07-08T06:37:36.295371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 이제 본격적으로 Null 을 채울 것입니다. null data 를 채우는 방법은 정말 많이 존재합니다. statistics 를 활용하는 방법도 있고, null data 가 없는 데이터를 기반으로 새로운 머신러닝 알고리즘을 만들어 예측해서 채워넣는 방식도 있습니다. 여기서는 statistics 를 활용하는 방법을 사용할 것입니다.\n- 여기서 statistics 는 train data 의 것을 의미합니다. 우리는 언제나 test 를 unseen 으로 둔 상태로 놔둬야 하며, train 에서 얻은 statistics 를 기반으로 test 의 null data 를 채워줘야 합니다.","metadata":{}},{"cell_type":"code","source":"df_train.groupby('Initial').mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.296788Z","iopub.status.idle":"2022-07-08T06:37:36.297164Z","shell.execute_reply.started":"2022-07-08T06:37:36.296973Z","shell.execute_reply":"2022-07-08T06:37:36.29699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Age 의 평균을 이용해 Null value를 채우도록 하겠습니다.\n- pandas dataframe 을 다룰 때에는 boolean array를 이용해 indexing 하는 방법이 참으로 편리합니다.\n- 아래 코드 첫줄을 해석하자면, isnull() 이면서 Initial 이 Mr 인 조건을 만족하는 row(탑승객) 의 'Age' 의 값을 33으로 치환한다 입니다.\n- loc + boolean + column 을 사용해 값을 치환하는 방법은 자주 쓰이므로 꼭 익숙해집시다.","metadata":{}},{"cell_type":"code","source":"df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22\ndf_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46\n\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22\ndf_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.299013Z","iopub.status.idle":"2022-07-08T06:37:36.299416Z","shell.execute_reply.started":"2022-07-08T06:37:36.299226Z","shell.execute_reply":"2022-07-08T06:37:36.299244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 여기서 간단하게 Null을 채웠지만, 좀 더 다양한 방법을 쓴 예시들이 다른 커널에 존재합니다.\n- https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling 보시면서 공부해보세요!\n- 이 외에도 다른 캐글러들의 커널을 보며 여러 참신한 아이디어를 살펴보세요!","metadata":{}},{"cell_type":"markdown","source":"# # # 3.1.2 Fill Null in Embarked","metadata":{}},{"cell_type":"code","source":"print('Embarked has ', sum(df_train['Embarked'].isnull()), ' Null values')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.301692Z","iopub.status.idle":"2022-07-08T06:37:36.302186Z","shell.execute_reply.started":"2022-07-08T06:37:36.301974Z","shell.execute_reply":"2022-07-08T06:37:36.301993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Embarked 는 Null value 가 2개이고, S 에서 가장 많은 탑승객이 있었으므로, 간단하게 Null 을 S로 채우겠습니다.\n- dataframe 의 fillna method 를 이용하면 쉽게 채울 수 있습니다. 여기서 inplace=True 로 하면 df_train 에 fillna 를 실제로 적용하게 됩니다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].fillna('S', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.304203Z","iopub.status.idle":"2022-07-08T06:37:36.304588Z","shell.execute_reply.started":"2022-07-08T06:37:36.304413Z","shell.execute_reply":"2022-07-08T06:37:36.30443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Change Age(continuous to categorical)","metadata":{}},{"cell_type":"markdown","source":"- Age 는 현재 continuous feature 입니다. 이대로 써도 모델을 세울 수 있지만, Age 를 몇개의 group 으로 나누어 category 화 시켜줄 수 도 있습니다. continuous 를 categorical 로 바꾸면 자칫 information loss 가 생길 수도 있습니다만, 본 튜토리얼에서는 다양한 방법을 소개하는 것이 목적이므로 진행하도록 하겠습니다.\n- 방법은 여러가지가 있습니다. dataframe 의 indexing 방법인 loc 를 사용하여 직접해줄 수 있고, 아니면 apply 를 사용해 함수를 넣어줄 수 있습니다.\n- 첫번째로 loc 를 사용한 방법입니다. loc 는 자주쓰게 되므로 그 사용법을 숙지하시면 좋습니다.\n- 나이는 10살 간격으로 나누겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Age_cat'] = 0\ndf_train.loc[df_train['Age'] < 10, 'Age_cat'] = 0\ndf_train.loc[(10 <= df_train['Age']) & (df_train['Age'] < 20), 'Age_cat'] = 1\ndf_train.loc[(20 <= df_train['Age']) & (df_train['Age'] < 30), 'Age_cat'] = 2\ndf_train.loc[(30 <= df_train['Age']) & (df_train['Age'] < 40), 'Age_cat'] = 3\ndf_train.loc[(40 <= df_train['Age']) & (df_train['Age'] < 50), 'Age_cat'] = 4\ndf_train.loc[(50 <= df_train['Age']) & (df_train['Age'] < 60), 'Age_cat'] = 5\ndf_train.loc[(60 <= df_train['Age']) & (df_train['Age'] < 70), 'Age_cat'] = 6\ndf_train.loc[70 <= df_train['Age'], 'Age_cat'] = 7\n\ndf_test['Age_cat'] = 0\ndf_test.loc[df_test['Age'] < 10, 'Age_cat'] = 0\ndf_test.loc[(10 <= df_test['Age']) & (df_test['Age'] < 20), 'Age_cat'] = 1\ndf_test.loc[(20 <= df_test['Age']) & (df_test['Age'] < 30), 'Age_cat'] = 2\ndf_test.loc[(30 <= df_test['Age']) & (df_test['Age'] < 40), 'Age_cat'] = 3\ndf_test.loc[(40 <= df_test['Age']) & (df_test['Age'] < 50), 'Age_cat'] = 4\ndf_test.loc[(50 <= df_test['Age']) & (df_test['Age'] < 60), 'Age_cat'] = 5\ndf_test.loc[(60 <= df_test['Age']) & (df_test['Age'] < 70), 'Age_cat'] = 6\ndf_test.loc[70 <= df_test['Age'], 'Age_cat'] = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.305801Z","iopub.status.idle":"2022-07-08T06:37:36.306572Z","shell.execute_reply.started":"2022-07-08T06:37:36.306375Z","shell.execute_reply":"2022-07-08T06:37:36.306396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 두번째로 간단한 함수를 만들어 apply 메소드에 넣어주는 방법입니다.\n- 훨씬 수월합니다.","metadata":{}},{"cell_type":"code","source":"def category_age(x):\n    if x < 10:\n        return 0\n    elif x < 20:\n        return 1\n    elif x < 30:\n        return 2\n    elif x < 40:\n        return 3\n    elif x < 50:\n        return 4\n    elif x < 60:\n        return 5\n    elif x < 70:\n        return 6\n    else:\n        return 7    \n    \ndf_train['Age_cat_2'] = df_train['Age'].apply(category_age)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.30806Z","iopub.status.idle":"2022-07-08T06:37:36.308478Z","shell.execute_reply.started":"2022-07-08T06:37:36.308297Z","shell.execute_reply":"2022-07-08T06:37:36.308315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 두가지 방법이 잘 적용되었다면, 둘다 같은 결과를 내야합니다.\n- 이를 확인하기 위해 Series 간 boolean 비교 후 all () 메소드를 사용합시다. all() 메소드는 모든 값이 True 면, True, 하나라도 False 가 있으면 False 를 줍니다.","metadata":{}},{"cell_type":"code","source":"print('1번 방법, 2번 방법 둘다 같은 결가르 내면 True 줘야함 --> ', (df_train['Age_cat']==df_train['Age_cat_2']).all())","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.309575Z","iopub.status.idle":"2022-07-08T06:37:36.310115Z","shell.execute_reply.started":"2022-07-08T06:37:36.309902Z","shell.execute_reply":"2022-07-08T06:37:36.309924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 둘중 편한 걸 선택하시면 됩니다.\n- 이제 중복되는 Age_cat컬럼고 원래 컬럼 Age를 제거하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train.drop(['Age', 'Age_cat_2'], axis=1, inplace=True)\ndf_test.drop(['Age'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.311795Z","iopub.status.idle":"2022-07-08T06:37:36.312382Z","shell.execute_reply.started":"2022-07-08T06:37:36.312187Z","shell.execute_reply":"2022-07-08T06:37:36.312207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Change Initial, Embarked and Sex (string to numerical)\n- 현재 Initial 은 Mr, Mrs, Miss, Master, Other 총 5개로 이루어져 있습니다. 이런 카테고리로 표현되어져 있는 데이터를 모델에 인풋으로 넣어줄 때 우리가 해야할 것은 먼저 컴퓨터가 인식할 수 있도록 수치화 시켜야 합니다.\n- map method 를 가지고 간단히 할 수 있습니다.\n- 사전 순서대로 정리하여 mapping 하겠습니다","metadata":{}},{"cell_type":"code","source":"df_train['Initial'] = df_train['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})\ndf_test['Initial'] = df_test['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.313856Z","iopub.status.idle":"2022-07-08T06:37:36.314801Z","shell.execute_reply.started":"2022-07-08T06:37:36.31458Z","shell.execute_reply":"2022-07-08T06:37:36.314603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Embarked 도 C, Q, S로 이루어져 있습니다. map 을 이용해 바꿔봅시다.\n- 그러기 앞서서, 특정 column 에 어떤 값들이 있는 지 확인해보는 방법을 잠깐 살펴보겠습니다. 간단히 unique() 메소드를 쓰거나, value_counts() 를 써서 count 까지 보는 방법이 있습니다.","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.315477Z","iopub.status.idle":"2022-07-08T06:37:36.315837Z","shell.execute_reply.started":"2022-07-08T06:37:36.315642Z","shell.execute_reply":"2022-07-08T06:37:36.315685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.319244Z","iopub.status.idle":"2022-07-08T06:37:36.31967Z","shell.execute_reply.started":"2022-07-08T06:37:36.319475Z","shell.execute_reply":"2022-07-08T06:37:36.319495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 위 두 방법을 사용해 Embarked가 S, C, Q 세가지로 이루어진 것을 볼 수 있습니다. 이제 map을 사용해봅시다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'] = df_train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\ndf_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.321227Z","iopub.status.idle":"2022-07-08T06:37:36.321624Z","shell.execute_reply.started":"2022-07-08T06:37:36.321444Z","shell.execute_reply":"2022-07-08T06:37:36.321462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 한번 Null 이 사라졌는지 확인해봅시다. Embarked Column만 가져온 것은 하나의 pandas의 Series 객체므로, isnull() 메소드를 사용해 Series의 값들이 null 인지 아닌지에 대한 boolean 값을 얻을 수 있습니다. 그리고 이것에 any() 를 사용하여, True 가 단하나라도 있을 시(Null이 한개라도 있을 시) True 를 반환해주게 됩니다. 우리는 Null 을 S로 다 바꿔주었으므로 False 를 얻게 됩니다","metadata":{}},{"cell_type":"code","source":"df_train['Embarked'].isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.323095Z","iopub.status.idle":"2022-07-08T06:37:36.323531Z","shell.execute_reply.started":"2022-07-08T06:37:36.323349Z","shell.execute_reply":"2022-07-08T06:37:36.323368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Sex 도 Female, male 로 이루어져 있습니다. map 을 이용해 바꿔봅시다.","metadata":{}},{"cell_type":"code","source":"df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\ndf_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.325208Z","iopub.status.idle":"2022-07-08T06:37:36.325604Z","shell.execute_reply.started":"2022-07-08T06:37:36.325425Z","shell.execute_reply":"2022-07-08T06:37:36.325443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 이제 각 feature 간의 상관관계를 한번 보려고 합니다. 두 변수간의 Pearson correlation 을 구하면 (-1, 1) 사이의 값을 얻을 수 있습니다. -1로 갈수록 음의 상관관계, 1로 갈수록 양의 상관관계를 의미하며, 0은 상관관계가 없다는 것을 의미합니다. 구하는 수식은 아래와 같습니다.","metadata":{}},{"cell_type":"markdown","source":"식: r(xy) = \n\n- 우리는 여러 feature 를 가지고 있으니 이를 하나의 maxtrix 형태로 보면 편할 텐데, 이를 heatmap plot 이라고 하며, dataframe 의 corr() 메소드와 seaborn 을 가지고 편하게 그릴 수 있습니다.\n","metadata":{}},{"cell_type":"code","source":"heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked','FamilySize', 'Initial', 'Age_cat'] ]\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14, 12))\nplt.title('Pearson Correlation of Features', y = 1.05, size = 15)\nsns.heatmap(heatmap_data.astype(float).corr(), linewidths = 0.1, vmax = 1.0, square = True, cmap = colormap, linecolor='white', annot=True, annot_kws={\"size\":16})\ndel heatmap_data","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.327089Z","iopub.status.idle":"2022-07-08T06:37:36.327491Z","shell.execute_reply.started":"2022-07-08T06:37:36.327318Z","shell.execute_reply":"2022-07-08T06:37:36.327335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- 우리가 EDA에서 살펴봤듯이, Sex와 Pclass 가 Survived에 상관관계가 어느정도 있음을 볼 수 이습니다.\n- 생각보다 fare 와 Embarked도 상관관계가 있음을 볼 수 있습니다.\n- 또한 우리가 여기서 얻을 수 있는 정보는 서로 강한 상관관계를 가지는 feature들이 없다는 것입니다.\n- 이것은 우리가 모델을 학습시킬 대, 불필요한 (redundant, superfluous)feature 가 없다는 것을 의미합니다. 1 또는 -1 의 상관관계를 가진 feature A,B 가 있다면, 우리가 얻을 수 있는 정보는 사실 하나일 거니까요.\n- 이제 실제로 모델을 학습시키기 앞서서 data preprocessing (전처리) 을 진행해보겠습니다. 거의 다 와갑니다. \n\n# # #  3.4 One-hot encoding on Initial and Embarked\n\n- 수치화시킨 카테고리 데이터를 그대로 넣어도 되지만, 모델의 선능을 높이기위해 oe-hot endcoding을 해줄 수 있습니다.\n- 수치화는 간단히 Mater == 0, Miss==1,  Mr==2, Mrs==3, Other==4로 매핑해주는 것을 말합니다.\n- One-hot encoding은 위 카테고리를 아래와 같이 (0,1) 로 이루어진 5차원의 벡터로 나타내는 것을 말합니다.\n\n\n\n- pandas 의 get_dummies 를 사용하여 쉽게 해결 할 수 있습니다.\n- 총 5개의 카테고리니, one-hotencoding을 하고 나면 새로운 5개의 column이 생겨납니다.\n- Initial 을 prefix로 두어서 구분이 쉽게 만들어 줍니다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\ndf_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.328514Z","iopub.status.idle":"2022-07-08T06:37:36.329022Z","shell.execute_reply.started":"2022-07-08T06:37:36.328799Z","shell.execute_reply":"2022-07-08T06:37:36.328819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.330556Z","iopub.status.idle":"2022-07-08T06:37:36.331091Z","shell.execute_reply.started":"2022-07-08T06:37:36.33082Z","shell.execute_reply":"2022-07-08T06:37:36.330846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보시다시피 오른쪽에 우리가 만들려고 했던 one-hot encoded columns 가 생성된 것이 보입니다.\n- Embarked 에도 적용하겠습니다. Initial때와 마찬가지로 one-hot encoding 을 사용해 표현하겠습니다.","metadata":{}},{"cell_type":"code","source":"df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')\ndf_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.333263Z","iopub.status.idle":"2022-07-08T06:37:36.33421Z","shell.execute_reply.started":"2022-07-08T06:37:36.333903Z","shell.execute_reply":"2022-07-08T06:37:36.33393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 아주 쉽게 one-hot encoding을 적용했습니다.\n- sklearn 로  labelencoder + OneHotEncoder 이용해도 one-hot encoding 이 가능합니다.\n- 다른 튜토리얼에서 한번 써보겠습니다. 여기서는 get_dummies 로 충분히 가능하게 때문에 get_dummies만으로 끝내겠습니다.\n- 가끔 category 가 100개가 넘어가는 경우가 있습니다. 이때 one-hot encoding 을 사용하면 column 이 100 개가 생겨, 학습시 매우 번거로울 경우가 있습니다. 이런 경우는 다른 방법을 사용하기도 하는데, 이는 다음에 한번 다뤄보겠습니다.\n\n### 3.5 Drop Columns\n- 필요한 columns만 남기고 다 지웁시다.\n","metadata":{}},{"cell_type":"code","source":"df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\ndf_test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.336027Z","iopub.status.idle":"2022-07-08T06:37:36.336979Z","shell.execute_reply.started":"2022-07-08T06:37:36.336658Z","shell.execute_reply":"2022-07-08T06:37:36.336687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.338182Z","iopub.status.idle":"2022-07-08T06:37:36.339309Z","shell.execute_reply.started":"2022-07-08T06:37:36.338984Z","shell.execute_reply":"2022-07-08T06:37:36.339013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.341093Z","iopub.status.idle":"2022-07-08T06:37:36.341871Z","shell.execute_reply.started":"2022-07-08T06:37:36.341558Z","shell.execute_reply":"2022-07-08T06:37:36.341601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # # #  4. Building machine learning model and predicting using the trained model\n    - 이제 준비가 다 되었으니 sklearn을 사용해 본격적으로 머신러닝 모델을 만들어봅시다.","metadata":{}},{"cell_type":"code","source":"#import all the ML packages\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skleran import metrics\nfrom sklearn model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.343556Z","iopub.status.idle":"2022-07-08T06:37:36.34452Z","shell.execute_reply.started":"2022-07-08T06:37:36.344223Z","shell.execute_reply":"2022-07-08T06:37:36.34426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Sklearn 은 머신러닝의 처음부터 끝까지가 다 있습니다. feature engineering, preprocessing, 지도 학습 알고리즘, 비지도 학습 알고리즘, 모델 평가, 파이프라인 등 머신러닝에 관련된 모든 작업들이 손쉬운 인터페이스로 구현되어 있습니다. 데이터 분석 + 머신러닝을 하고싶다면, 이 라이브러리는 반드시 숙지해야합니다.\n- 파이썬 라이브러리를 활용한 머신러닝(Introduction to machine learning with Python)책을 사서 공부하시길 매우 추천해드립니다.\n- 지금 타이타닉 문제는 target class(survived)가 있으며, target class 는 0, 1로 이루어져 있으므로(binary) binary classfication 문제입니다.\n- 우리가 지금 가지고 있는 train set 의 survived를 제외한 input 을 가지고 모델을 최적화시켜서 각 샘플(탑승객)의 생존유무를 판단하는 모델을 만들어 냅니다.\n- 그 후 모델이 학습하지 않았던 test set 을 input 으로 주어서 test set 의 각 샘플(탑승객)의 생존 유무를 예측해봅니다.","metadata":{}},{"cell_type":"markdown","source":"# # # # 4.1 Preparation - Split dataset into train, valid, test set\n\n- 가장 먼저, 학습에 쓰일 데이터와, target label(Survived)를 분리합니다. drop 을 사용해 간단히 할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_train = df_train.drop('Survived', axis = 1).values\ntarget_label = df_train['Survived'].values\nX_test = df_test.values","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.346243Z","iopub.status.idle":"2022-07-08T06:37:36.346764Z","shell.execute_reply.started":"2022-07-08T06:37:36.346497Z","shell.execute_reply":"2022-07-08T06:37:36.346521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 보통 트레인, 테스트만 언급되지만 실제 좋은 모델을 만들기 위해서 우리는 validset 을 따로 만들어 모델을 평가해보아야 합니다.\n- 마치 국가대표 축구팀이 훈련을 하고 바로 월드컵 경기에 나가는 것이 아니라 훈련 후에 평가전을 거쳐 팀의 훈련 정도를 확인하 월드컵에 나가는 것과 같습니다.\n- train_test_split을 이용하여 쉽게 데이터를 분리할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"X_tr, X_vld, y_tr, y_vld = train_test_split(X_train, target_label, test_size=0.3, random_state=2018)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.348346Z","iopub.status.idle":"2022-07-08T06:37:36.349237Z","shell.execute_reply.started":"2022-07-08T06:37:36.348905Z","shell.execute_reply":"2022-07-08T06:37:36.348933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- sklearn 에서는 여러 머신러닝 알고리즘을 지원해 줍니다 열거하기엔 너무 많으므로, 직접 documentation에 들어가 보시길 추천합니다.  http://scikit-learn.org/stable/supervised_learning.html#supervised-learning  여기에 들어가시면 지원되는 알고리즘 수에 놀라실 겁니다.\n- 본 튜토리얼에서는 랜덤 포레스트 모델을 사용하도록 하겠습니다.\n- 랜덤포레스트는 결정트리기반 모델이며, 여러 결정 트리들을 앙상블한 모델입니다. 더 구체적인 모델 설명은 려러 블로그들 참고하시면 될 것이고, 저도 한번 추후 다뤄보겠습니다.\n- 각 머신러닝 알고리즘에는 여러 파리미터들이 있습니다. 랜덤포레스트분류기도 n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf 등 여러 파라미터들이 존재합니다. 이럿들이 어떻게 세팅되냐에 따라 같은 데이터셋이라 하더라도 모델의 성능이 잘라집니다.\n- 파라미터 튜닝은 시간, 경험, 알고리즘에 대한 이해 등이 필요합니다. 결국 많이 써봐야 모델도 잘 세울 수 있는 것이죠. 그래서 캐글을 추천합니다. 여러 데이터셋을 가지고 모델을 이리저리 써봐야 튜닝하는 감이 생길테니까요!\n- 일단 지금은 튜토리얼이니 파라미터 튜닝은 잠시 제쳐두기로 하고, 기본 default 세팅으로 진행하겠습니다.\n모델 객체를 만들고, fit 메소드로 학습시킵니다.\n- 그런 후 valid set input 을 넣어주어 예측값(X_vld sample(탑승객)의 생존여부)를 얻습니다.\n\n# # #  4.2  Model gengeration and prediction\n","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_tr, y_tr)\nprediction = model.predict(X_vld)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.350722Z","iopub.status.idle":"2022-07-08T06:37:36.351275Z","shell.execute_reply.started":"2022-07-08T06:37:36.350979Z","shell.execute_reply":"2022-07-08T06:37:36.351002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 단 세줄만으로 여러분은 모델을 세우고, 예측까지 해봤습니다.\n- 자, 이제 모델의 성능을 한번 살펴보겠습니다.","metadata":{}},{"cell_type":"code","source":"print('총 {}명 중 {:.2f}% 정확도로 생존을 맞춤'.format(y_vld.shape[0], 100 * metrics.accuracy_score(prediction, y_vld)))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.353485Z","iopub.status.idle":"2022-07-08T06:37:36.353837Z","shell.execute_reply.started":"2022-07-08T06:37:36.353669Z","shell.execute_reply":"2022-07-08T06:37:36.353685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#  # # #  4.3 Feature importance \n- 학습된 모델은 feature importance 를 가지게 되는데, 우리는 이것을 확인하여 지금 만든 모델이 어떤 feature 에 영향을 많이 받았는 지 확인할 수 있습니다.\n- 쉽게 말해, 10 = 4x1 + 2x2 + 1*x3 을 생각하면, 우리는 x1이 결과값(10)에 큰 영향을 준다고 생각 할 수 있습니다. feature importance 는 4, 2, 1 을 이야기하며, x1이 가장 큰 값(4)를 가지므로, 이 모델에 가장 큰 영향을 미친다고 말할 수 있습니다.\n- 학습된 모델은 기본적으로 featureimportances 를 가지고 있어서 쉽게 그 수치를 얻을 수 있습니다.\n- pandas series 를 이용하면 쉽게 sorting 을 하여 그래프를 그릴 수 있습니다.\n","metadata":{}},{"cell_type":"code","source":"from pandas import Series\n\nfeature_importance = model.feature_importances_\nSeries_feat_imp = Series(feature_importance, index=df_test.columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:36.355079Z","iopub.status.idle":"2022-07-08T06:37:36.355768Z","shell.execute_reply.started":"2022-07-08T06:37:36.355555Z","shell.execute_reply":"2022-07-08T06:37:36.355576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nSeries_feat_imp.sort_values(ascending=True).plot.barh()\nplt.xlabel('Feature importance')\nplt.ylabel('Feature')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:37:47.843652Z","iopub.execute_input":"2022-07-08T06:37:47.844432Z","iopub.status.idle":"2022-07-08T06:37:47.86586Z","shell.execute_reply.started":"2022-07-08T06:37:47.844389Z","shell.execute_reply":"2022-07-08T06:37:47.864094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 우리가 얻은 모델에서는 Fare가 가장 큰 영향력을 가지며, 그 뒤로 Initial_2, Age_cat, Pclass가 차례로 중요도를 가집니다.\n- 사실 feature importance 는 지금 모델에서의 importance 를 나타냅니다. 만약 다른 모델을 사용하게 된다면 \n- 이 feature importance 를 보고 실제로 Fare 가 중요한 feature 일 수 있다고 판단을 내릴 수는 있지만, 이것은 결국 모델에 귀속되는 하나의 결론이므로 통계적으로 좀 더 살펴보긴 해야합니다.\n- featuure importance 를 가지고 좀 더 정확도가 높은 모델을 얻기 위해 feature selection 을 할 수도 있고, 좀 더 빠른 모델을 위해 feature 제거를 할 수 있습니다.\n","metadata":{}},{"cell_type":"markdown","source":"# # # 4.4 Prediction on Test set\n\n- 이제 모델이 학습하지 않았던(보지 않았던) 테스트셋을 모델에 주어서, 생존여부를 예측해보겠습니다.\n- 이 결과는 실제로 submission(제출용) 이므로 결과는 leaderboard 에서 확인할 수 있습니다.\n- 캐글에서 준 파일, gender_submission.csv 파일을 읽어서 제출 준비를 하겠습니다.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/gender_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"- 이제 testset 에 대하여 예측을 하고, 결과를 csv 파일로 저장해보겠습니다.","metadata":{}},{"cell_type":"markdown","source":"# # # 5. Conclusion\n\n- 정말 수고하셨습니다. 여러분은 titanic dataset 을 가지고 data science 를 경험해보셨습니다.\n- 이걸로 끝이 아닙니다. 앞으로 배울 것이 너무나 무궁무진합니다.\n- 좀 더 참신한 feature engineering, 머신 러닝 모델 hyperparameter tunning, ensembling 등, 무궁무진합니다..\n- 꾸준히 커널공부를 하시면 실력이 꾸준히 늘겁니다.\n- 포기하지 마시고 재밌게 하시면 됩니다\n- 본 튜토리얼을 따라해주셔서 감사하며, 제 유투브 채널에 강의도 올려놨으니 한번 보시면 됩니다!\n- 본 튜토리얼을 따라하시다가, 혹시 문제가 있거나, 궁금한 사항이 있으면 언제든 말씀해주세요! 저도 더 성장하길 원합니다!","metadata":{}}]}